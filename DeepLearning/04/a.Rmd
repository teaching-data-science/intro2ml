## Training neural networks
```{r, include=FALSE, cache=FALSE}
ap = adjust_path(paste0(getwd(), "/figure"))
```

Training of neural nets is composed of two iterative steps:

  1. __Forward pass__: The information of the inputs flow through the model to produce a prediction. Based on that, we compute the empirical loss.
  2. __Backward pass__: Information of the error of the predictions flows backwards through the model and weights are updated in such a way the error is reduced.

- The error is calculated by a loss function $L(y, f(x, \thetab))$, of the true target $y$ and the networks output $f(x, \thetab)$.


## Training neural networks

- For regression, we typically use the L2 loss:
\[
  L(y, f(x, \thetab)) = \frac{1}{2}(y - f(x, \thetab))^2
\]

- For classification we typically apply binary/categorical crossentropy:
\[
  L(y, f(x, \thetab)) = \Big[y log \ f(x, \thetab) + (1 - y) log(1 - f(x, \thetab)) \Big]
\]

Evaluated on the data we call this the risk
\[
  \riske = \sumin \Lxyi,
\]

## Gradient descent

- To minimize the risk we need to recall the method of gradient descent in numerical
  optimization.

- At a point $\theta^{[t]}$ we can calculate the gradient $\nabla \risk$, which always points in the direction of the steepest ascent.

- Thus $-\nabla \risk$ points in the direction of the steepest descent!


## Gradient descent

- At a point $\theta^{[t]}$ during minimization, we can improve by doing the following step:
\[
      \thetab^{[t + 1 ]}  = \thetab^{[t]} - \alpha \nabla \risk\left(\thetab^{[t]}\right)
\]

   "Walking down the hill, towards the valley."

- $\alpha$ determines the length of the step and is called learning rate.

## Gradient descent

\begin{figure}
  \centering
    \includegraphics[width=10.2cm]{`r ap("gd_example.png")`}
     \caption{Example of gradient descent with $\theta=(w_1, w_2)$.}
\end{figure}

## Weight updates with Backpropagation

- To update each weight $w \in \thetab$ in the network we need their gradients with regards to the risk.

- Since weights are stacked in layers inside the network, we need to repeatedly apply the *chain rule of calculus*. This process is called __backpropagation__.

- After obtaining the gradients we can update the weights by gradient descent
\[
\thetab^{[t + 1]} = \thetab^{[t]} - \alpha \cdot \frac{1}{n} \cdot \sumin \nabla_\theta L\left(\yi, f(\xi ~|~ \thetab^{[t]})\right)
\]
