\documentclass[11pt,compress,t,notes=noshow]{beamer}
\usepackage[]{graphicx}\usepackage[]{color}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\newcommand{\SweaveOpts}[1]{}  % do not interfere with LaTeX
\newcommand{\SweaveInput}[1]{} % because they are not real TeX commands
\newcommand{\Sexpr}[1]{}       % will only be parsed by R



\usepackage[english]{babel}
\usepackage{dsfont}
\newcommand\bmmax{2}
\usepackage{bm}
\usepackage{bbm}
\usepackage{verbatim}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{csquotes}
\usepackage{multirow}
\usepackage{longtable}
\usepackage{enumerate}
\usepackage[absolute,overlay]{textpos}
\usepackage{psfrag}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{eqnarray}
\usepackage{multimedia}
\usepackage{media9}
\usepackage{arydshln}
\usepackage{tabularx}
\usepackage{placeins}
\usepackage{tikz}
\usepackage{setspace}
\usepackage{wrapfig}
\usepackage{tcolorbox}
\usepackage[export]{adjustbox}
\usepackage{siunitx}
\usetikzlibrary{shapes,arrows,automata,positioning,calc}
\def\signed #1{{\leavevmode\unskip\nobreak\hfil\penalty50\hskip1em
  \hbox{}\nobreak\hfill #1%
  \parfillskip=0pt \finalhyphendemerits=0 \endgraf}}

\newsavebox\mybox
\newenvironment{aquote}[1]
  {\savebox\mybox{#1}\begin{quote}\openautoquote\hspace*{-.7ex}}
  {\unskip\closeautoquote\vspace*{1mm}\signed{\usebox\mybox}\end{quote}}
  
\tikzset{
  %Define standard arrow tip
  >=stealth',
  %Define style for boxes
  punkt/.style={
    rectangle,
    rounded corners,
    draw=black, very thick,
    text width=6.5em,
    minimum height=2em,
    text centered},
  % Define arrow style
  pil/.style={
    ->,
    thick,
    shorten <=2pt,
    shorten >=2pt,}
}
\usepackage{subfig}

%new environments

\newenvironment{vbframe}  %frame with breaks and verbatim
{
 \begin{frame}[containsverbatim,allowframebreaks]
}
{
\end{frame}
}

\newenvironment{vframe}  %frame with verbatim without breaks (to avoid numbering one slided frames)
{
 \begin{frame}[containsverbatim]
}
{
\end{frame}
}

\newenvironment{blocki}[1]   % itemize block
{
 \begin{block}{#1}\begin{itemize}
}
{
\end{itemize}\end{block}
}

\newenvironment{fragileframe}[2]{  %fragile frame with framebreaks
\begin{frame}[allowframebreaks, fragile, environment = fragileframe]
\frametitle{#1}
#2}
{\end{frame}}


\newcommand{\myframe}[2]{  %short for frame with framebreaks
\begin{frame}[allowframebreaks]
\frametitle{#1}
#2
\end{frame}}

\newcommand{\remark}[1]{
  \textbf{Remark:} #1
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% basic latex stuff
\newcommand{\pkg}[1]{{\fontseries{b}\selectfont #1}} %fontstyle for R packages
\newcommand{\lz}{\vspace{0.5cm}} %vertical space
\newcommand{\dlz}{\vspace{1cm}} %double vertical space
\newcommand{\oneliner}[1] % Oneliner for important statements
{\begin{block}{}\begin{center}\begin{Large}#1\end{Large}\end{center}\end{block}}


%\usetheme{lmu-lecture}
\usepackage{../style/lmu-lecture}

\let\code=\texttt
\let\proglang=\textsf

\setkeys{Gin}{width=0.9\textwidth}



\title{Introduction to Machine Learning}
\author{Bernd Bischl}
\institute{Department of Statistics -- LMU Munich}
\date{Winter term 2021}

\setbeamertemplate{frametitle}{\expandafter\uppercase\expandafter\insertframetitle}



\begin{document}




\input{../latex-math/basic-math}
\input{../latex-math/basic-ml}
\input{../latex-math/ml-nn}

\lecturechapter{1}{Deep Learning- Introduction}
\lecture{Deep Learning - Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame} {What is Deep Learning}
\begin{center}
\includegraphics[width=0.95\textwidth]{plots/learning.pdf}
\end{center}
\vspace{-.5cm}
\begin{itemize}
\item Deep learning is the use of artificial neural networks to
construct models on large amounts of (unstructured) data.
\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame} {Deep Learning and Neural Networks}
\begin{itemize}
\item Deep learning and neural networks are mostly equivalent.
\vspace{.3cm}
\item Deep learning itself is not \textit{new}:
\begin{itemize}
\item Neural networks have been around since the 70s
\item \textit{Deep} neural networks, i.e., networks with multiple hidden layers, are not much younger.
\end{itemize}
\vspace{.3cm}
\item Why everybody is talking about deep learning now:
\begin{itemize}
\item Specialized, powerful hardware allows the training of huge neural networks that are able to push the state-of-the-art on extremely difficult problems.
\item Large amount of data is available.
\item Special network architectures for image/text data.
\item Better optimization and regularization strategies.
\end{itemize}
\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Image Classification with Neural Networks}
\begin{aquote}{Y. Bengio}
Machine learning algorithms, inspired by the brain, based on learning multiple levels of representation/abstraction.   
\end{aquote}
\begin{overlayarea}{\textwidth}{\textheight}
\centering
\only<1>{\includegraphics[width=0.7\textwidth]{plots/bird1.pdf}}
\only<1>{\\ \footnotesize{Caption 1}}
\only<2>{\includegraphics[width=0.7\textwidth]{plots/bird2.pdf}}
\only<2>{\\ \footnotesize{Caption 2}}
\only<3>{\includegraphics[width=0.7\textwidth]{plots/bird3.pdf}}
\only<3>{\\ \footnotesize{Caption 3}}
\only<4>{\includegraphics[width=0.7\textwidth]{plots/bird4.pdf}}
\only<4>{\\ \footnotesize{Caption 4}}
\end{overlayarea}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame} {Possible use-cases}
\textbf{Deep learning can be extremely valuable if the data has these properties:}
\vspace{.2cm}
\begin{itemize}
\item It is high dimensional.
\item Each single feature itself is not very informative but only a combination of them might be.
\item There is a large amount of training data.
\end{itemize}
\vspace{.7cm}
\textbf{This implies that for tabular data, deep learning is almost never the correct model choice.}
\vspace{.2cm}
\begin{itemize}
\item Models like random forests or gradient boosting will outperform deep learning most of the time.
\item One exception is data with categorical features with many levels.
\end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame} {Possible use-case: Images}
\begin{itemize}
\item \textbf{High Dimensional}: A color image with $255 \times 255$ (3 Colors) pixels already has $195075$ features.
\vspace{.1cm}
\item \textbf{Informative}: A single pixel is not meaningful in itself.
\vspace{.1cm}
\item \textbf{Training Data}: Depending on applications huge amounts of data are available.
\end{itemize}
\vspace{.3cm}
Architecture: \textbf{C}onvolutional \textbf{N}eural \textbf{N}etworks (CNN)
\begin{figure}
\centering
\scalebox{.85}{\includegraphics{plots/three_channels.png}}
%https://medium.com/@RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148
\end{figure}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame} {Possible use-case: Images}
\begin{figure}
\centering
\scalebox{.7}{\includegraphics{plots/classification.png}}
\end{figure}
\textbf{Image classification} tries to predict a single label for each image (Alex Krizhevsky (2009))
\footnotesize CIFAR-10 is a well-known dataset used for image classification. It consists of $60,000$ $32x32$ color images containing one of $10$ object classes, with $6000$ images per class. 
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame} {Possible use-case: Images}
\begin{figure}
\centering
\scalebox{0.8}{\includegraphics{plots/maskrcnn.png}}
\end{figure}
\textbf{Object Detection} (Kaiming He (2017))
\footnotesize Mask R-CNN is a general framework for instance segmentation, which efficiently detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance.
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame} {Possible use-case: Images}
\begin{figure}
\centering
\scalebox{.8}{\includegraphics{plots/segmentation.png}}
\end{figure}
\textbf{Image segmentation} partitions the image into (multiple) segments (Hyeonwoo Noh (2015))
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame} {Possible use-case: Text}
\begin{itemize}
\item \textbf{High Dimensional}: Each word can be a single feature (~300000 words in the German language).
\vspace{.1cm}
\item \textbf{Informative}: A single word does not provide much context.
\vspace{.1cm}
\item \textbf{Training Data}: Huge amounts of text data available.
\end{itemize}
\vspace{.3cm}
Architecture: \textbf{R}ecurrent \textbf{N}eural \textbf{N}etworks (RNN)
\begin{figure}
\centering
\scalebox{.75}{\includegraphics{plots/hierarchical_sequence.png}}
%https://arxiv.org/abs/1506.01057
\end{figure}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame} {Possible use-case: Text}
Applications:
\vspace{.7cm}
\begin{itemize}
\item \textbf{N}atural \textbf{L}anguage \textbf{P}rocessing, e.g.,
\begin{itemize}
\item Sentiment Analysis
\vspace{.3cm}
\item Email Classification
\vspace{.3cm}
\item Chat-bots
\vspace{.3cm}
\item $...$
\end{itemize}
\vspace{.7cm}
\item Modeling Sequential Data (Time-Series, Speech)
\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame} {Possible use-case: Text}
\begin{figure}
\centering
\scalebox{.9}{\includegraphics{plots/nmt.png}}
\end{figure}
\textbf{Machine Translation} (e.g. google translate) 
Neural machine translation exploits neural networks to predict the likelihood of a sequence of words, typically modeling entire sentences in a single integrated model.
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame} {Applications of Deep Learning: Speech}
\begin{figure}
\centering
\scalebox{.9}{\includegraphics{plots/speech_goog.jpg}}
\end{figure}
\textbf{Speech Recognition and Generation} (e.g. google assistant)
Neural network extracts features from audio data in order to classify emotions in speech.
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\endlecture
\end{document}
