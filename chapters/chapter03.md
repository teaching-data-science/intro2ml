---
title: 'Chapter 3: Supervised Classification'
description:
  " This Chapter treats the supervised classification task in more detail. We will see examples of binary and multiclass classification and the difference of the discriminative and the generative approach. Especially, we will treat logistic regression, linear and quadratic discriminant analysis, naive bayes and k-NN classification."
type: chapter
prev: /chapter02
next: /chapter04
id: 1
---


<section class="index-module-chapter-c72e2d57">
  <h2 class="index-module-chapter-title-5e0ebe7a">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter03-01-classification-classificationtasks">Chapter 3.1: Classification Tasks</a>

  </h2>
  <p class="index-module-chapter-desc-de526628">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter03-01-classification-classificationtasks"> Classification is a type of ML task in which learn functions assign class labels to observation/feature vectors. In this chapter, you will get an idea about the meaning of classification as well as the structure of classification problems. We will do so by providing some examples of binary and multiclass classification tasks.</a>
  </p>
</section>





<section class="index-module-chapter-c72e2d57">
  <h2 class="index-module-chapter-title-5e0ebe7a">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter03-02-classification-basicdefinitions">Chapter 3.2: Basic Definitions</a>

  </h2>
  <p class="index-module-chapter-desc-de526628">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter03-02-classification-basicdefinitions"> Classifiers should be distinguished from the perspective of producing labels, probabilities, and scores. This chapter argues that we should differentiate between scoring and probabilistic classifiers. Additionally, we explain two fundamental approaches for constructing classifiers: the generative approach and the discriminant approach.</a>
  </p>
</section>





<section class="index-module-chapter-c72e2d57">
  <h2 class="index-module-chapter-title-5e0ebe7a">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter03-03-classification-linearclassifiers">Chapter 3.3: Linear Classifiers</a>

  </h2>
  <p class="index-module-chapter-desc-de526628">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter03-03-classification-linearclassifiers"> Linear classifiers are an essential subclass of classification models. This section provides a mathematical definition of a linear classifier and depicts differences between linear and non-linear decision boundaries.</a>
  </p>
</section>





<section class="index-module-chapter-c72e2d57">
  <h2 class="index-module-chapter-title-5e0ebe7a">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter03-04-classification-logisticregression">Chapter 3.4: Logistic Regression</a>

  </h2>
  <p class="index-module-chapter-desc-de526628">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter03-04-classification-logisticregression"> This chapter helps you understand how logistic regression works and what logistic function is. Additionally, you will learn the Bernoulli loss. Your practical task is to train a logistic regression with R and mlr3, and you can practice transforming linear classifiers into non-linear classifiers.</a>
  </p>
</section>





<section class="index-module-chapter-c72e2d57">
  <h2 class="index-module-chapter-title-5e0ebe7a">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter03-05-classification-discriminantanalysis">Chapter 3.5: Discriminant Analysis</a>

  </h2>
  <p class="index-module-chapter-desc-de526628">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter03-05-classification-discriminantanalysis"> Linear discriminant analysis (LDA) follows a generative approach to find a linear combination of features that characterizes or separates two or more classes of objects or events. We can formally show that LDA is a linear classifier. QDA is a direct generalization of LDA, where the class densities are Gaussians with unequal covariances. This chapter investigates LDA and QDA.</a>
  </p>
</section>





<section class="index-module-chapter-c72e2d57">
  <h2 class="index-module-chapter-title-5e0ebe7a">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter03-06-classification-naviebayes">Chapter 3.6: Naive Bayes</a>

  </h2>
  <p class="index-module-chapter-desc-de526628">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter03-06-classification-naviebayes"> In this chapter, you are going to get familiar with an important type of classifier, namely the Naive Bayes. For some types of probability models, naive Bayes classifiers can be trained very efficiently in a supervised learning setting.</a>
  </p>
</section>





<section class="index-module-chapter-c72e2d57">
  <h2 class="index-module-chapter-title-5e0ebe7a">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter03-07-classification-knn">Chapter 3.7: 	K-Nearest Neighbors</a>

  </h2>
  <p class="index-module-chapter-desc-de526628">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter03-07-classification-knn"> k-NN is a lazy classifier which has no real training step; it merely stores the complete data required during predictions. As will be shown in this chapter, because of not being based on distributional or strong functional assumptions, k-NN can theoretically model situations with arbitrary complexity. As a practical task, you would also learn how to fit different classifiers in mlr3.</a>
  </p>
</section>




