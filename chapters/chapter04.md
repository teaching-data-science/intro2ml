---
title: 'Chapter 4: Performance Evaluation'
description:
  " This Chapter treats the challenge of evaluating the performance of a model. We will introduce different performance measures for regression and classification tasks, explain the problem of overfitting, the difference between training and test error and finally present a variety of resampling techniques."
type: chapter
prev: /chapter03
next: /chapter05
id: 1
---


<section class="index-module-chapter-c72e2d57">
  <h2 class="index-module-chapter-title-5e0ebe7a">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter04-01-evaluation-introduction">Chapter 4.1: Introduction</a>

  </h2>
  <p class="index-module-chapter-desc-de526628">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter04-01-evaluation-introduction"> How well does a model perform on data from the same data generating process? ML performance evaluation provides clear protocols for model validation. By completing this chapter, you would know what performance estimation is and why it is essential.</a>
  </p>
</section>





<section class="index-module-chapter-c72e2d57">
  <h2 class="index-module-chapter-title-5e0ebe7a">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter04-02-evaluation-measuresregression">Chapter 4.2: Measures Regression</a>

  </h2>
  <p class="index-module-chapter-desc-de526628">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter04-02-evaluation-measuresregression"> This chapter makes you familiar with simple performance measures for regression. In particular, mean squared error (MSE), mean absolute error (MAE), and a straightforward generalization of R2 are discussed.</a>
  </p>
</section>





<section class="index-module-chapter-c72e2d57">
  <h2 class="index-module-chapter-title-5e0ebe7a">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter04-03-evaluation-measuresclassification">Chapter 4.3: Measures Classification</a>

  </h2>
  <p class="index-module-chapter-desc-de526628">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter04-03-evaluation-measuresclassification"> A classifier predicts either class labels or class probabilities. Hence, its performance can be evaluated based on these two notions. This chapter teaches you some simple performance measures for classification, including the misclassification error rate (MCE), accuracy (ACC), confusion matrix, and Brier score (BS).</a>
  </p>
</section>





<section class="index-module-chapter-c72e2d57">
  <h2 class="index-module-chapter-title-5e0ebe7a">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter04-04-evaluation-measuresclassificationroc">Chapter 4.4: Measures Classification ROC</a>

  </h2>
  <p class="index-module-chapter-desc-de526628">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter04-04-evaluation-measuresclassificationroc"> From the confusion matrix (binary case), we can calculate "ROC" metrics. Historically, ROC was developed by engineers during world war II for detecting enemy objects in battlefields. This chapter makes you familiar with the ROC.</a>
  </p>
</section>





<section class="index-module-chapter-c72e2d57">
  <h2 class="index-module-chapter-title-5e0ebe7a">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter04-05-evaluation-measuresclassificationrocvisualization">Chapter 4.5: Measures Classification ROC Visualisation</a>

  </h2>
  <p class="index-module-chapter-desc-de526628">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter04-05-evaluation-measuresclassificationrocvisualization"> In this chapter, you learn how to deal with unbalanced binary classification problems and how to visualize some ROC curves. As a practical task, you would calculate and plot the ROC.</a>
  </p>
</section>





<section class="index-module-chapter-c72e2d57">
  <h2 class="index-module-chapter-title-5e0ebe7a">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter04-06-evaluation-overfitting">Chapter 4.6: Overfitting</a>

  </h2>
  <p class="index-module-chapter-desc-de526628">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter04-06-evaluation-overfitting"> Because of too many hypotheses and not enough data to tell them apart, it is possible to have overfitting. This happens when algorithms model patterns beyond the data generating process. In this chapter, you will get to know when exactly overfitting happens, and your practical task is to examine how k-NN overfits for small ks.</a>
  </p>
</section>





<section class="index-module-chapter-c72e2d57">
  <h2 class="index-module-chapter-title-5e0ebe7a">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter04-07-evaluation-trainingerror">Chapter 4.7: Training Error</a>

  </h2>
  <p class="index-module-chapter-desc-de526628">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter04-07-evaluation-trainingerror"> There are two types of errors: training error and test error. The focus of this chapter is on the former. We will see that many evaluating measures (such as R2, likelihood, AIC, BIC) are based on the training error.</a>
  </p>
</section>





<section class="index-module-chapter-c72e2d57">
  <h2 class="index-module-chapter-title-5e0ebe7a">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter04-08-evaluation-testerror">Chapter 4.8: Test Error</a>

  </h2>
  <p class="index-module-chapter-desc-de526628">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter04-08-evaluation-testerror"> In ML, we are usually given one complete data set, and we would like to fit one model on that data set. The training error evaluation does not work in this situation since it cannot be used to estimate the future performance of the model. Measuring the test error would be a solution. This chapter argues that we would also need splitting and resampling tools.</a>
  </p>
</section>





<section class="index-module-chapter-c72e2d57">
  <h2 class="index-module-chapter-title-5e0ebe7a">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter04-09-evaluation-resampling">Chapter 4.9: Resampling</a>

  </h2>
  <p class="index-module-chapter-desc-de526628">
  <a class="link-module-root-46224d00 link-module-hidden-7e2d93b5" href="/chapter04-09-evaluation-resampling"> In the present chapter, you would understand the idea of resampling and would get familiar with cross-validation, bootstrapping, and subsampling. You would also learn how to define and conduct a resampling strategy with mlr3. Additionally, you can find out how to apply benchmark experiments and interpret the benchmark results.</a>
  </p>
</section>




