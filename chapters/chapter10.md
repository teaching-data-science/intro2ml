---
title: 'Chapter 10: Advanced Risk Minimization'
description:
  " This chapter treats the theory of risk minimization in more depth." 
type: chapter
prev: /chapter09
next: /chapter011
id: 8
---


<section class="c72e2d57">
  <h2 class="_5e0ebe7a">
  <a class="_46224d00 _7e2d93b5" href="/chapter10-01-advriskmin-riskminimizer">Chapter 10.1: Risk Minimizers</a>

  </h2>
  <p class="de526628">
  <a class="_46224d00 _7e2d93b5" href="/chapter10-01-advriskmin-riskminimizer">We introduce important theoretical in risk minimization: Risk minimizer, Bayes risk, Bayes regret, consistent learners and the optimal constant model. </a>
  </p>
</section>





<section class="c72e2d57">
  <h2 class="_5e0ebe7a">
  <a class="_46224d00 _7e2d93b5" href="/chapter10-02-advriskmin-pseudoresiduals">Chapter 10.2: Pseudo-Residuals</a>

  </h2>
  <p class="de526628">
  <a class="_46224d00 _7e2d93b5" href="/chapter10-02-advriskmin-pseudoresiduals"> We introduce the concept of pseudo-residuals and discuss its relation to gradient descent.</a>
  </p>
</section>





<section class="c72e2d57">
  <h2 class="_5e0ebe7a">
  <a class="_46224d00 _7e2d93b5" href="/chapter10-03-advriskmin-l2">Chapter 10.3: L2-loss</a>

  </h2>
  <p class="de526628">
  <a class="_46224d00 _7e2d93b5" href="/chapter10-03-advriskmin-l2"> In this section, we revisit the L2 loss and derive risk minimizer and optimal constant model. </a>
  </p>
</section>





<section class="c72e2d57">
  <h2 class="_5e0ebe7a">
  <a class="_46224d00 _7e2d93b5" href="/chapter10-04-advriskmin-l1">Chapter 10.4: L1-loss</a>

  </h2>
  <p class="de526628">
  <a class="_46224d00 _7e2d93b5" href="/chapter10-04-advriskmin-l1"> In this section, we revisit the L1 loss and derive risk minimizer and optimal constant model. </a>
  </p>
</section>





<section class="c72e2d57">
  <h2 class="_5e0ebe7a">
  <a class="_46224d00 _7e2d93b5" href="/chapter10-05-advriskmin-further-losses">Chapter 10.5: Advanced Regression Losses</a>

  </h2>
  <p class="de526628">
  <a class="_46224d00 _7e2d93b5" href="/chapter10-05-advriskmin-further-losses"> In this section, we introduce and discuss the following advanced regression losses: Huber, log-cosh, Cauchy, log-barrier, epsilon-insensitive, and quantile loss. </a>
  </p>
</section>





<section class="c72e2d57">
  <h2 class="_5e0ebe7a">
  <a class="_46224d00 _7e2d93b5" href="/chapter10-06-advriskmin-classification-01">Chapter 10.6: 0-1-loss</a>

  </h2>
  <p class="de526628">
  <a class="_46224d00 _7e2d93b5" href="/chapter10-06-advriskmin-classification-01"> In this section, we revisit the 0-1-loss and derive risk minimizer and optimal constant model.  </a>
  </p>
</section>





<section class="c72e2d57">
  <h2 class="_5e0ebe7a">
  <a class="_46224d00 _7e2d93b5" href="/chapter10-07-advriskmin-classification-bernoulli">Chapter 10.7: Bernoulli Loss</a>

  </h2>
  <p class="de526628">
  <a class="_46224d00 _7e2d93b5" href="/chapter10-07-advriskmin-classification-bernoulli"> In this section, we introduce the Bernoulli loss and derive risk minimizer and optimal constant model. We further discuss the connection between Bernoulli loss minimization and tree splitting according to the entropy criterion. </a>
  </p>
</section>





<section class="c72e2d57">
  <h2 class="_5e0ebe7a">
  <a class="_46224d00 _7e2d93b5" href="/chapter10-08-advriskmin-classification-brier">Chapter 10.8: Brier Score</a>

  </h2>
  <p class="de526628">
  <a class="_46224d00 _7e2d93b5" href="/chapter10-08-advriskmin-classification-brier"> In this section, we introduce the Brier score and derive risk minimizer and optimal constant model. We further discuss the connection between Brier score minimization and tree splitting according to the Gini index. </a>
  </p>
</section>





<section class="c72e2d57">
  <h2 class="_5e0ebe7a">
  <a class="_46224d00 _7e2d93b5" href="/chapter10-09-advriskmin-classification-further-losses">Chapter 10.9: Advanced Classification Losses</a>

  </h2>
  <p class="de526628">
  <a class="_46224d00 _7e2d93b5" href="/chapter10-09-advriskmin-classification-further-losses"> In this section, we introduce and discuss the following advanced classification losses: (Squared) hinge loss, L2 loss on scores, exponential loss, and AUC loss. </a>
  </p>
</section>





<section class="c72e2d57">
  <h2 class="_5e0ebe7a">
  <a class="_46224d00 _7e2d93b5" href="/chapter10-10-advriskmin-maxlik-1">Chapter 10.10: Maximum Likelihood Estimization vs. Empirical Risk Minimization I</a>

  </h2>
  <p class="de526628">
  <a class="_46224d00 _7e2d93b5" href="/chapter10-10-advriskmin-maxlik-1"> In this section, we discuss the connection between maximum likelihood estimation and risk minimization. We discuss the correspondence between a Gaussian error distribution and L2 loss. </a>
  </p>
</section>





<section class="c72e2d57">
  <h2 class="_5e0ebe7a">
  <a class="_46224d00 _7e2d93b5" href="/chapter10-11-advriskmin-maxlik-2">Chapter 10.11: Maximum Likelihood Estimization vs. Empirical Risk Minimization II</a>

  </h2>
  <p class="de526628">
  <a class="_46224d00 _7e2d93b5" href="/chapter10-11-advriskmin-maxlik-2"> In this section, we discuss the connection between maximum likelihood estimation and risk minimization for further losses (L1 loss, Bernoulli loss). </a>
  </p>
</section>




