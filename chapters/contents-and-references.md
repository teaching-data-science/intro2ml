---
title: 'Contents and References'
description: null
prev: null
next: null
type: chapter
id: 1
---

This course offers an introductory and applied overview of "supervised" Machine Learning. This includes:

- ML Basics 
- Supervised Regression 
- Supervised Classification
- Performance Evaluation
- Classification and Regression Trees
- Random Forests
- Parameter Tuning
- Practical Advice

The course is of an introductory nature and geared towards students with some statistics background. It is aimed at a practical and operational understanding of the covered algorithms and models, with less emphasis on theory and formalism. The accompanying exercises, demos and tutorials are a mix of theoretical and practical assignments, the latter in R (mostly with [`mlr3`](https://mlr3.mlr-org.com/)).


## Concept

The course is organized as a digital lecture, which should be as self-contained 
and enable self-study as much as possible. 
The major part of the material is provided as slide sets with lecture videos.
We have also prepared interactive tutorials where you can answer multiple choice 
questions, and learn how to apply the covered methods in R on some short 
coding exercises. 
Our plan is to extend this self-study material over the next months and years.

## Prerequisites

The course is targeted at *ML beginners* with a basic, university level, education in maths and statistics:

- Basic linear algebra: vectors, matrices, determinants 
- Simple calculus: derivatives, integrals, gradients
- Some probability theory: probability, random variables, distributions
- Basic statistics knowledge: descriptive statistics, estimators.  
- (Linear) modelling from a statistics perspective will help, but is not required.
- Working knowledge of R



## Major References

The course material covers all exam relevant topics. For a deeper study of the courses and additional machine learning topics, we recommend the following literature:

* G. James, D. Witten, T. Hastie, R. Tibshirani. An Introduction to Statistical Learning. MIT Press, 2010. [link](http://www-bcf.usc.edu/~gareth/ISL/)

## More Advanced Books

The following books are great, but quite detailed and involved, and more geared towards a larger lecture in a Master's degree.

* T. Hastie, R. Tibshirani, J. Friedman. The Elements of Statistical Learning. Springer, 2009. [link](https://web.stanford.edu/~hastie/ElemStatLearn/)
* K. Murphy. Machine Learning: a Probabilistic Perspective [link](https://www.cs.ubc.ca/~murphyk/MLbook/)
* E. Alpaydin. Introduction to Machine Learning. MIT Press, 2010. [link](http://www.cmpe.boun.edu.tr/~ethem/i2ml2e/)
* C. M. Bishop. Pattern Recognition and Machine Learning. Springer, 2006. [link](http://research.microsoft.com/en-us/um/people/cmbishop/prml/)

## R

We use the *mlr3* package for machine learning in R.

* Central project page and learning ressources: https://mlr3.mlr-org.com/
* Github page: https://github.com/mlr-org/mlr3

The first link contains a section "Ressources" which lists all available background information to enable you to learn the toolkits.
Please study those. Most important (for you as new users) are the book, the gallery, the cheatsheets. 
Use the usual R package manuals for formal library documentation.
It might be good to watch the 2 short intro video from the UseR 2019 to get a quick overview in less than an hour.