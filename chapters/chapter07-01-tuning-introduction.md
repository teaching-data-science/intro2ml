---
title: 'Chapter 7.1: Introduction'
description:
  ' While model parameters are optimizied during training, hyperparameters are specified before the training. In this Section, we will motivate why it is crucial to find good values for the hyperparameters, i.e. to "tune" the hyperparameters.'
prev: /chapter06-06-forests-discussion
next: /chapter07-02-tuning-problemdefinition
type: subchapter
id: 1
---

<exercise id="1" title="Video Lecture">

<iframe width="100%" height="480" src="https://www.youtube.com/embed/lG4Ul1Liq-U" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

</exercise>

<exercise id="2" title="Slides">

<object data="pdfs/7/slides-tuning-intro.pdf" type="application/pdf" style="width:100%;height:480px">
    <embed src="pdfs/7/slides-tuning-intro.pdf" type="application/pdf" />
</object>

</exercise>



<exercise id="3" title="Quiz">
Which statements are true?
<choice>
<opt text="Tuning means optimizing hyperparameters." correct="true">
</opt>
<opt text="Doing tuning well is hard; nested resampling can help." correct="true">
</opt>
<opt text="Good tuning is crucial to achieve good performance for all ML algorithms.">
</opt>
<opt text="Tuning optimizes the inner loss.">
</opt>
</choice>
</exercise>
